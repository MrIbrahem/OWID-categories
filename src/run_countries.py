#!/usr/bin/env python3
"""
OWID Commons Countries Categorizer

This script automatically adds country-specific categories to OWID graph files on Wikimedia Commons.
It reads JSON files generated by Phase 1 and adds categories in the format:
    Category:Our World in Data graphs of {Country}

Requirements:
- Python 3.10+
- mwclient library
- python-dotenv library
- Valid Wikimedia Commons bot credentials in .env file

Usage:
    python run_countries.py                              # Process all countries
    python run_countries.py --dry-run                    # Test without making edits
    python run_countries.py --limit 5                    # Process first 5 countries only
    python run_countries.py --files-per-country 10       # Process 10 files per country
"""

import argparse
import mwclient
import logging
import sys
import time
from pathlib import Path
from typing import Dict, Optional

from categorize.wiki import (
    connect_to_commons,
    load_credentials,
    add_category_to_page,
    ensure_category_exists,
    get_category_member_count,
    get_edit_delay,
)
from categorize.utils import (
    setup_logging,
    load_json_file,
    normalize_country_name,
    build_category_name,
    get_parent_category,
)


# Configuration
COUNTRIES_DIR = Path("output/countries")
LOG_FILE = Path("logs/categorize_countries.log")


def process_files(
    site: mwclient.Site,
    file_path: Path,
    dry_run: bool = False,
    graphs_only: bool = True,
    files_per_country: Optional[int] = None
) -> Dict[str, int]:
    """
    Process a single country JSON file and add categories to its files.

    Args:
        site: Connected mwclient Site
        file_path: Path to country JSON file
        dry_run: If True, don't actually make edits
        graphs_only: If True, only process graph files (not maps)
        files_per_country: Optional limit on number of files to process per country

    Returns:
        Dictionary with statistics (added, skipped, errors)
    """
    stats = {
        "added": 0,
        "skipped": 0,
        "errors": 0
    }

    # Load country data
    data = load_json_file(file_path)
    if not data:
        stats["errors"] += 1
        return stats

    iso3 = data.get("iso3")
    country = data.get("country")
    files = data.get("graphs", [])

    if not country:
        logging.error(f"No country name in {file_path}")
        stats["errors"] += 1
        return stats

    # Normalize country name and build category name
    normalized_country = normalize_country_name(country)
    category = build_category_name(country, "country", "graphs")

    # Check if category already has enough files when files_per_country is set
    if files_per_country:
        current_member_count = get_category_member_count(site, category)
        if current_member_count >= files_per_country:
            logging.info(f"\nSkipping {iso3} ({normalized_country}): Category already has {current_member_count} files (>= {files_per_country} requested)")
            return stats

        logging.info(f"\nProcessing {iso3} ({normalized_country}): Category has {current_member_count} files, will add up to {files_per_country} files")
    else:
        logging.info(f"\nProcessing {iso3} ({normalized_country}): {len(files)} files")

    # Apply per-country file limit if specified
    if files_per_country:
        files = files[:files_per_country]
        logging.info(f"Limiting to {files_per_country} file(s) per country")

    # Ensure the category page exists before adding files to it
    parent_category = get_parent_category("country")
    if not ensure_category_exists(site, category, parent_category, country, dry_run):
        logging.error(f"Failed to ensure category '{category}' exists for {normalized_country}, skipping this country")
        stats["errors"] += 1
        return stats

    # Process files
    for file in files:
        title = file.get("title")
        if not title:
            logging.warning(f"File missing title in {file_path}")
            stats["errors"] += 1
            continue

        # Add category
        if add_category_to_page(site, title, category, dry_run):
            stats["added"] += 1
        else:
            stats["skipped"] += 1

        # Rate limiting
        if not dry_run:
            time.sleep(get_edit_delay())

    return stats


def main(dry_run: bool = False, limit: Optional[int] = None, files_per_country: Optional[int] = None):
    """
    Main execution function for countries categorization.

    Args:
        dry_run: If True, don't actually make edits
        limit: Optional limit on number of countries to process
        files_per_country: Optional limit on number of files to process per country
    """
    setup_logging(LOG_FILE)

    logging.info("=" * 80)
    logging.info("OWID Commons Countries Categorizer")
    logging.info("=" * 80)

    if dry_run:
        logging.info("Running in DRY RUN mode - no actual edits will be made")

    if files_per_country:
        logging.info(f"Processing {files_per_country} file(s) per country")

    # Load credentials
    username, password = load_credentials()
    if not username or not password:
        logging.error("Failed to load credentials from .env file")
        logging.error("Please create a .env file with WM_USERNAME and PASSWORD")
        sys.exit(1)

    # Connect to Commons
    site = connect_to_commons(username, password)
    if not site:
        logging.error("Failed to connect to Wikimedia Commons")
        sys.exit(1)

    # Check if countries directory exists
    if not COUNTRIES_DIR.exists():
        logging.error(f"Countries directory not found: {COUNTRIES_DIR}")
        logging.error("Please run Phase 1 (fetch_commons_files.py) first")
        sys.exit(1)

    # Get all country JSON files
    country_files = sorted(COUNTRIES_DIR.glob("*.json"))

    if not country_files:
        logging.error(f"No country JSON files found in {COUNTRIES_DIR}")
        sys.exit(1)

    logging.info(f"Found {len(country_files)} country files")

    # Apply limit if specified
    if limit:
        country_files = country_files[:limit]
        logging.info(f"Processing limited to first {limit} countries")    # Process each country file
    total_stats = {
        "added": 0,
        "skipped": 0,
        "errors": 0,
        "countries_processed": 0,
        "countries_skipped": 0
    }

    for file_path in country_files:
        stats = process_files(site, file_path, dry_run=dry_run, files_per_country=files_per_country)

        # If no files were added or skipped, the country was skipped entirely
        if stats["added"] == 0 and stats["skipped"] == 0 and stats["errors"] == 0:
            total_stats["countries_skipped"] += 1
        else:
            total_stats["added"] += stats["added"]
            total_stats["skipped"] += stats["skipped"]
            total_stats["errors"] += stats["errors"]
            total_stats["countries_processed"] += 1

    # Final summary
    logging.info("\n" + "=" * 80)
    logging.info("FINAL SUMMARY")
    logging.info("=" * 80)
    logging.info(f"Countries processed: {total_stats['countries_processed']}")
    logging.info(f"Countries skipped (already have enough files): {total_stats['countries_skipped']}")
    logging.info(f"Categories added: {total_stats['added']}")
    logging.info(f"Already had category (skipped): {total_stats['skipped']}")
    logging.info(f"Errors: {total_stats['errors']}")
    logging.info("=" * 80)

    if dry_run:
        logging.info("\nThis was a DRY RUN - no actual edits were made")
        logging.info("Run without --dry-run flag to make actual edits")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Add country categories to OWID graph files on Wikimedia Commons"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Run in dry-run mode (no actual edits)"
    )
    parser.add_argument(
        "--limit",
        type=int,
        help="Limit processing to first N countries (for testing)"
    )
    parser.add_argument(
        "--files-per-country",
        type=int,
        help="Limit processing to N files per country (for testing)"
    )

    args = parser.parse_args()

    main(dry_run=args.dry_run, limit=args.limit, files_per_country=args.files_per_country)
